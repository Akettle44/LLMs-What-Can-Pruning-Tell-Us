{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook for Exploring CKA applied to BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch_cka import CKA\n",
    "import datasets\n",
    "import transformers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from bertviz import model_view, head_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize Dataset\n",
    "\n",
    "Note that padding is being used based on the maxlen right now. This is a requirement to concat items into batches in PyTorch. Reduction was being used prior. \n",
    "\n",
    "TODO: Trim the max_len down to something more reasonable so there aren't a bunch of useless tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup chosen task and metric\n",
    "task = \"cola\"\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "dataset = datasets.load_dataset(\"glue\", task)\n",
    "metric = datasets.load_metric(\"glue\", task)\n",
    "\n",
    "# Figure out dataset characteristics\n",
    "max_len_train = len(max(dataset['train']['sentence'][:]))\n",
    "max_len_val = len(max(dataset['validation']['sentence'][:]))\n",
    "max_len_test = len(max(dataset['test']['sentence'][:]))\n",
    "max_len = max(max_len_train, max_len_val, max_len_test)\n",
    "\n",
    "# Tokenize Dataset\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased', use_fast=True)\n",
    "# preprocess function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['sentence'], padding='max_length', max_length=max_len)\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function (not currently used)\n",
    "\n",
    "#def collate_fn(batch):\n",
    "#    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
    "#    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
    "#    #label = torch.stack([item['label'] for item in batch])\n",
    "#    token_type_ids = torch.stack([item['token_type_ids'] for item in batch])\n",
    "#    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'token_type_ids': token_type_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 8551\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1043\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1063\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "tokenized_dataset = encoded_dataset.with_format('torch', columns=['input_ids', 'token_type_ids', 'attention_mask'])\n",
    "print(tokenized_dataset)\n",
    "\n",
    "train_loader = DataLoader(tokenized_dataset['train'], batch_size=batch_size)\n",
    "val_loader = DataLoader(tokenized_dataset['validation'], batch_size=batch_size)\n",
    "test_loader = DataLoader(tokenized_dataset['test'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If CUDA OOM is being thrown, try reducing the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'bert_pruning_model'\n",
    "num_labels=2\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu' # Check for device\n",
    "\n",
    "# Import two models for comparison\n",
    "#model1 = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels, output_attentions=True)\n",
    "model1 = transformers.BertForSequenceClassification.from_pretrained(model_directory, num_labels=num_labels, output_attentions=True)\n",
    "model2 = transformers.BertForSequenceClassification.from_pretrained(model_directory, num_labels=num_labels, output_attentions=True)\n",
    "\n",
    "model1 = model1.to(device)\n",
    "model2 = model2.to(device)\n",
    "\n",
    "# Choose layers to factor into CKA calculation\n",
    "model1_names = [f\"bert.encoder.layer.{i}.attention\" for i in range(0, 12)]\n",
    "model2_names = [s for s in model1_names] # Perform Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/school/grad/spring24/bert_pruning/PyTorch-Model-Compare/torch_cka/cka.py:145: UserWarning: Dataloader for Model 2 is not given. Using the same dataloader for both models.\n",
      "  warn(\"Dataloader for Model 2 is not given. Using the same dataloader for both models.\")\n",
      "| Comparing features |:  80%|███████▉  | 214/268 [00:36<00:09,  5.69it/s]"
     ]
    }
   ],
   "source": [
    "cka = CKA(model1, model2, model1_name=\"Model1\", model2_name=\"Model2\", model1_layers=model1_names, model2_layers=model2_names, device=device)\n",
    "cka.compare(train_loader)\n",
    "results = cka.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results of CKA calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "cka.plot_results(\"plot\", \"BERT Comparison\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
