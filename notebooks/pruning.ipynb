{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook for Exploring Pruning of BERT: Inspired from: https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb#scrollTo=YOCrQwPoIrJG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task selected using Huggingface's Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "import datasets\n",
    "import transformers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from bertviz import model_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task\n",
    "CoLA outputs a binary label of gramatically correct or not. It was deemed the easiest place to start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112339/1311342779.py:6: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = datasets.load_metric(\"glue\", task)\n",
      "/home/andrew/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setup chosen task and metric\n",
    "task = \"cola\"\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "batch_size = 16\n",
    "dataset = datasets.load_dataset(\"glue\", task)\n",
    "metric = datasets.load_metric(\"glue\", task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 8551\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1043\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1063\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#print(dataset)\n",
    "#print(dataset[\"train\"][0])\n",
    "\n",
    "print(dataset.with_format(\"torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric(name: \"glue\", features: {'predictions': Value(dtype='int64', id=None), 'references': Value(dtype='int64', id=None)}, usage: \"\"\"\n",
      "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
      "Args:\n",
      "    predictions: list of predictions to score.\n",
      "        Each translation should be tokenized into a list of tokens.\n",
      "    references: list of lists of references for each translation.\n",
      "        Each reference should be tokenized into a list of tokens.\n",
      "Returns: depending on the GLUE subset, one or several of:\n",
      "    \"accuracy\": Accuracy\n",
      "    \"f1\": F1 score\n",
      "    \"pearson\": Pearson Correlation\n",
      "    \"spearmanr\": Spearman Correlation\n",
      "    \"matthews_correlation\": Matthew Correlation\n",
      "Examples:\n",
      "\n",
      "    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
      "    >>> references = [0, 1]\n",
      "    >>> predictions = [0, 1]\n",
      "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
      "    >>> print(results)\n",
      "    {'accuracy': 1.0}\n",
      "\n",
      "    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
      "    >>> references = [0, 1]\n",
      "    >>> predictions = [0, 1]\n",
      "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
      "    >>> print(results)\n",
      "    {'accuracy': 1.0, 'f1': 1.0}\n",
      "\n",
      "    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n",
      "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
      "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
      "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
      "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
      "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
      "\n",
      "    >>> glue_metric = datasets.load_metric('glue', 'cola')\n",
      "    >>> references = [0, 1]\n",
      "    >>> predictions = [0, 1]\n",
      "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
      "    >>> print(results)\n",
      "    {'matthews_correlation': 1.0}\n",
      "\"\"\", stored examples: 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'matthews_correlation': 0.047619047619047616}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metric)\n",
    "\n",
    "# Using metric\n",
    "fake_preds = np.random.randint(0, 2, size=(64,))\n",
    "fake_labels = np.random.randint(0, 2, size=(64,))\n",
    "metric.compute(predictions=fake_preds, references=fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 7592, 1010, 2023, 2028, 6251, 999, 102, 1998, 2023, 6251, 3632, 2007, 2009, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 8551\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1043\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1063\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Define tokenizer\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(checkpoint, use_fast=True)\n",
    "# Example\n",
    "print(tokenizer(\"Hello, this one sentence!\", \"And this sentence goes with it.\"))\n",
    "\n",
    "#print(f\"Sentence: {dataset['train'][0]['sentence']}\")\n",
    "\n",
    "# preprocess function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['sentence'], truncation=True)\n",
    "\n",
    "preprocess_function(dataset['train'][:5])\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Grab BERT for sequence classification\n",
    "\n",
    "num_labels = 2\n",
    "model = transformers.BertForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = \"matthews_correlation\"\n",
    "model_name = checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = transformers.TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_key = \"validation\"\n",
    "trainer = transformers.Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 535/2675 [25:22<1:41:31,  2.85s/it]\n",
      "  2%|â–         | 1/66 [08:49<9:33:23, 529.29s/it]\n",
      " 19%|â–ˆâ–Š        | 498/2675 [00:21<01:37, 22.27it/s]\n",
      "\n",
      "\n",
      "                                                  \n",
      "\n",
      " 19%|â–ˆâ–‰        | 504/2675 [00:22<01:38, 22.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4882, 'grad_norm': 12.448992729187012, 'learning_rate': 1.6261682242990654e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–‰        | 534/2675 [00:23<01:34, 22.71it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                        \n",
      "                                                  \n",
      "\n",
      " 20%|â–ˆâ–ˆ        | 535/2675 [00:23<01:34, 22.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4358927607536316, 'eval_matthews_correlation': 0.5127103010689016, 'eval_runtime': 0.5811, 'eval_samples_per_second': 1794.867, 'eval_steps_per_second': 113.577, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 999/2675 [00:45<01:14, 22.41it/s]\n",
      "\n",
      "\n",
      "                                                  \n",
      "\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1002/2675 [00:45<01:15, 22.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2895, 'grad_norm': 8.363648414611816, 'learning_rate': 1.2523364485981309e-05, 'epoch': 1.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 1068/2675 [00:48<01:10, 22.90it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                        \n",
      "                                                   \n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1070/2675 [00:49<01:10, 22.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4896464943885803, 'eval_matthews_correlation': 0.544509467622167, 'eval_runtime': 0.5894, 'eval_samples_per_second': 1769.678, 'eval_steps_per_second': 111.983, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1500/2675 [01:10<00:52, 22.22it/s]\n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1503/2675 [01:10<00:53, 21.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1915, 'grad_norm': 0.3836360275745392, 'learning_rate': 8.785046728971963e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1605/2675 [01:15<00:47, 22.44it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                        \n",
      "                                                   \n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1605/2675 [01:16<00:47, 22.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5909231901168823, 'eval_matthews_correlation': 0.5806473000395166, 'eval_runtime': 0.5812, 'eval_samples_per_second': 1794.563, 'eval_steps_per_second': 113.558, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2000/2675 [01:36<00:31, 21.65it/s]\n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2003/2675 [01:36<00:31, 21.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1283, 'grad_norm': 9.708556175231934, 'learning_rate': 5.046728971962617e-06, 'epoch': 3.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2138/2675 [01:43<00:25, 21.38it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                        \n",
      "                                                   \n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2140/2675 [01:43<00:25, 21.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.983931303024292, 'eval_matthews_correlation': 0.5572696682585848, 'eval_runtime': 0.6233, 'eval_samples_per_second': 1673.34, 'eval_steps_per_second': 105.887, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2498/2675 [02:02<00:08, 21.83it/s]\n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2504/2675 [02:02<00:07, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0786, 'grad_norm': 0.07026872783899307, 'learning_rate': 1.308411214953271e-06, 'epoch': 4.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2675/2675 [02:10<00:00, 25.44it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                        \n",
      "                                                   \n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2675/2675 [02:10<00:00, 25.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9713311195373535, 'eval_matthews_correlation': 0.57368884664922, 'eval_runtime': 0.5795, 'eval_samples_per_second': 1799.816, 'eval_steps_per_second': 113.891, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "                                                   \n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2675/2675 [02:13<00:00, 20.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 133.1197, 'train_samples_per_second': 321.177, 'train_steps_per_second': 20.095, 'train_loss': 0.22554543753650702, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2675, training_loss=0.22554543753650702, metrics={'train_runtime': 133.1197, 'train_samples_per_second': 321.177, 'train_steps_per_second': 20.095, 'total_flos': 454848611954580.0, 'train_loss': 0.22554543753650702, 'epoch': 5.0})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:00<00:00, 113.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5909231901168823, 'eval_matthews_correlation': 0.5806473000395166, 'eval_runtime': 0.6084, 'eval_samples_per_second': 1714.414, 'eval_steps_per_second': 108.486, 'epoch': 5.0}\n",
      "0.5806473000395166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ret = trainer.evaluate()\n",
    "print(ret)\n",
    "print(ret['eval_matthews_correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "trainer.save_model(\"bert_pruning_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model == trained_model\n",
    "\n",
    "#for p1, p2 in zip(model.parameters(), trained_model.parameters()):\n",
    "#    if(p1.data.ne(p2.data).sum() > 0):\n",
    "#        print('False')\n",
    "#print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "trained_model = transformers.BertForSequenceClassification.from_pretrained('bert_pruning_model', num_labels=num_labels, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sparisty of the network\n",
    "def calcSparsity(model):\n",
    "    zeros = 0\n",
    "    elements = 0\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "\n",
    "        # Layer was pruned if orig exists\n",
    "        #parsed_name = name.split('_orig')\n",
    "        # Layer was pruned\n",
    "        #if(len(parsed_name) == 2 and parsed_name[0] in parameter_names):\n",
    "\n",
    "        zero_count = torch.sum(param==0.0).item()\n",
    "        zeros += zero_count\n",
    "\n",
    "        element_count = param.numel()\n",
    "        elements += element_count\n",
    "\n",
    "    if(elements == 0):\n",
    "        return 0\n",
    "\n",
    "    return zeros / elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the parameters that you wish to prune\n",
    "parameters_to_prune = []\n",
    "parameter_names = []\n",
    "for name, module in trained_model.named_modules():\n",
    "\n",
    "    # Self-Attention\n",
    "    #if isinstance(module, transformers.models.bert.modeling_bert.BertSelfAttention):\n",
    "    #    parameters_to_prune.extend([\n",
    "    #            (module.query, 'weight'),\n",
    "    #            (module.key, 'weight'),\n",
    "    #            (module.value, 'weight'),\n",
    "    #        ])\n",
    "    #print(name)\n",
    "    #parameter_names.append(name)\n",
    "    #parameter_names.extend([name + '.query', name + '.key', name + '.value'])\n",
    "\n",
    "    # Linear: Includes linear layers in attention head as well\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        parameters_to_prune.append((module, 'weight'))\n",
    "        parameter_names.append(name + '.weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.9\n",
    ")\n",
    "\n",
    "for module,name in parameters_to_prune:\n",
    "    prune.remove(module, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7030577077820607"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcSparsity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Section for Training, Evaluating, and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/andrew/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8551/8551 [00:02<00:00, 4144.17 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1043/1043 [00:00<00:00, 4161.73 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1063/1063 [00:00<00:00, 4279.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Setup chosen task and metric\n",
    "task = \"cola\"\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "batch_size = 16\n",
    "dataset = datasets.load_dataset(\"glue\", task)\n",
    "metric = datasets.load_metric(\"glue\", task)\n",
    "model_directory = 'bert_pruning_model'\n",
    "\n",
    "# Figure out dataset characteristics\n",
    "max_len_train = len(max(dataset['train']['sentence'][:]))\n",
    "max_len_val = len(max(dataset['validation']['sentence'][:]))\n",
    "max_len_test = len(max(dataset['test']['sentence'][:]))\n",
    "max_len = max(max_len_train, max_len_val, max_len_test)\n",
    "\n",
    "# Tokenize Dataset\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased', use_fast=True)\n",
    "# preprocess function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['sentence'], padding='max_length', max_length=max_len)\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "#def collate_fn(batch):\n",
    "#    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
    "#    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
    "#    labels = torch.stack([item['labels'] for item in batch])\n",
    "#    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'Bill whistled past the house.', 'label': -1, 'idx': 0, 'input_ids': [101, 3021, 26265, 2627, 1996, 2160, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'sentence': 'The sooner you call, the more carefully I will word the letter.', 'label': -1, 'idx': 7, 'input_ids': [101, 1996, 10076, 2017, 2655, 1010, 1996, 2062, 5362, 1045, 2097, 2773, 1996, 3661, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(encoded_dataset['test'][0])\n",
    "print(encoded_dataset['test'][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset to torch with torch specs\n",
    "tr_dataset = encoded_dataset.with_format(\"torch\")\n",
    "\n",
    "#collate_fn=collate_fn\n",
    "\n",
    "train_loader = DataLoader(tr_dataset['train'], batch_size=16)\n",
    "val_loader = DataLoader(tr_dataset['validation'], batch_size=16)\n",
    "test_loader = DataLoader(tr_dataset['test'], batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_loader):\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[96], line 25\u001b[0m, in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     23\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[1;32m     24\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[0;32m---> 25\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: input_ids, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: attention_mask, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: labels}\n",
      "Cell \u001b[0;32mIn[96], line 25\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[1;32m     24\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[0;32m---> 25\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: input_ids, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: attention_mask, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: labels}\n",
      "\u001b[0;31mKeyError\u001b[0m: 'labels'"
     ]
    }
   ],
   "source": [
    "# Test out BertViz\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu' # Check for device\n",
    "model = transformers.BertForSequenceClassification.from_pretrained(model_directory, num_labels=num_labels, output_attentions=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Set test environment\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/glue/glue.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### NOTE: All of this code is direct PyTorch. Trying to use huggingface caused the fine tuning to fail when attempting to print out attention masks.\n",
    "###       We need to convert to PyTorch to do the pruning anyways so it makes sense to simply stay there\n",
    "\n",
    "metric_name = \"matthews_correlation\"\n",
    "metric = datasets.load_metric(\"glue\", task)\n",
    "models = []\n",
    "\n",
    "# Note: The pruning strength is for the subset of the neurons that you want to prune (defined by the paramater list created in the build parameter list function #\n",
    "def buildParameterList(model):\n",
    "    parameters_to_prune = []\n",
    "    for name, module in model.named_modules():\n",
    "        # Linear: Includes linear layers in attention head as well\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            parameters_to_prune.append((module, 'weight'))\n",
    "    return parameters_to_prune\n",
    "\n",
    "# NOTE: Metric is defined globally\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1) # TODO: switch to torch?\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def evaluateUnstructuredPruningOnBert(model_directory, dataset, tokenizer, pruning_strength=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], num_labels=2):\n",
    "\n",
    "    pruning_results = []\n",
    "\n",
    "    # Try different pruning methods\n",
    "    for p_strength in pruning_strength:\n",
    "\n",
    "        # Load model\n",
    "        test_model = transformers.BertForSequenceClassification.from_pretrained(model_directory, num_labels=num_labels, output_attentions=True)\n",
    "\n",
    "        # Choose layers to prune\n",
    "        pruning_params = buildParameterList(test_model)\n",
    "\n",
    "        if(p_strength > 0):\n",
    "\n",
    "            # Perform pruning\n",
    "            prune.global_unstructured(\n",
    "                pruning_params,\n",
    "                pruning_method=prune.L1Unstructured,\n",
    "                amount=p_strength\n",
    "            )\n",
    "\n",
    "            # Make pruning permenant\n",
    "            for module,name in pruning_params:\n",
    "                prune.remove(module, name)\n",
    "\n",
    "        models.append(test_model)\n",
    "\n",
    "        sparsity = calcSparsity(test_model)\n",
    "        print(f\"Pruning strength: {p_strength}, Sparsity: {sparsity}\")\n",
    "\n",
    "        # Create evaluator\n",
    "        evaluator = buildTrainer(test_model, dataset, tokenizer)\n",
    "\n",
    "        # Evaluate performance on BERT \n",
    "        results = evaluator.evaluate()\n",
    "        metric_res = results['eval_matthews_correlation']\n",
    "\n",
    "        pruning_results.append((sparsity, metric_res))\n",
    "        \n",
    "    return pruning_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning strength: 0, Sparsity: 0.0\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 19 but got size 17 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert_pruning_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m p_res \u001b[38;5;241m=\u001b[39m \u001b[43mevaluateUnstructuredPruningOnBert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 99\u001b[0m, in \u001b[0;36mevaluateUnstructuredPruningOnBert\u001b[0;34m(model_directory, dataset, tokenizer, pruning_strength, num_labels)\u001b[0m\n\u001b[1;32m     96\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m buildTrainer(test_model, dataset, tokenizer)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Evaluate performance on BERT \u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m metric_res \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_matthews_correlation\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    102\u001b[0m pruning_results\u001b[38;5;241m.\u001b[39mappend((sparsity, metric_res))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/transformers/trainer.py:3467\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3464\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3466\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3467\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3468\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3470\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3471\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3477\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/transformers/trainer.py:3674\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3672\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mpad_across_processes(labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m   3673\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((labels))\n\u001b[0;32m-> 3674\u001b[0m     \u001b[43mall_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_prediction_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   3678\u001b[0m \u001b[38;5;66;03m# Gather all tensors and put them back on the CPU if we have done enough accumulation steps.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:326\u001b[0m, in \u001b[0;36mEvalLoopContainer.add\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_nested_concat \u001b[38;5;28;01melse\u001b[39;00m [tensors]\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_nested_concat:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mappend(tensors)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:140\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, Mapping):\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n\u001b[1;32m    143\u001b[0m         {k: nested_concat(t, new_tensors[k], padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    144\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/bertenv/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:99\u001b[0m, in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     96\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m atleast_1d(tensor2)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n\u001b[1;32m    102\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m (tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 19 but got size 17 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "model_directory = 'bert_pruning_model'\n",
    "p_res = evaluateUnstructuredPruningOnBert(model_directory, encoded_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0.5932805322494611), (0.0781175271463504, 0.5779181076197502), (0.15623504515892755, 0.559827888599451), (0.23435257230527795, 0.5337975510473064), (0.3124700903178551, 0.5179391870486293), (0.3905876174642055, 0.37130794726495275), (0.4687051446105559, 0.07583845140032916), (0.5468226626231331, 0.018148342420931135), (0.6249401897694835, 0.004186223773740697), (0.7030577077820607, -0.03534585767137743)]\n"
     ]
    }
   ],
   "source": [
    "print(p_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "sparsities = []\n",
    "metric_results = []\n",
    "\n",
    "for sparsity, met in p_res:\n",
    "    sparsities.append(sparsity)\n",
    "    metric_results.append(met)\n",
    "\n",
    "plt.plot(sparsities, metric_results, label=\"Matthews Coefficient\", color=\"blue\")\n",
    "plt.title(\"Matthew's Coefficient as a Function of Network Sparsity\")\n",
    "plt.xlabel(\"Sparsity (%)\")\n",
    "plt.ylabel(\"Matthews Coefficient (Higher Better)\")\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXTRA CODE THAT DIDN'T GET USED ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override BertTrainer class to specify custom functionality\n",
    "class BertTrainer(transformers.Trainer):\n",
    "    # Overrides Trainer prediction so that attention maps can be output as well\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        # Move inputs to device\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "\n",
    "        # Forward pass (prediction)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        attentions = outputs[2]\n",
    "\n",
    "        attentions = torch.stack(list(attentions), dim=0)\n",
    "\n",
    "        print(type(loss), type(logits), type(attentions))\n",
    "\n",
    "        return (loss, logits, attentions) if not prediction_loss_only else (loss, None, None)\n",
    "\n",
    "    #def evaluate(self, eval_dataset, ignore_keys, metric_key_prefix = 'eval', **gen_kwargs):\n",
    "\n",
    "def buildTrainer(model, encoded_dataset, tokenizer):\n",
    "\n",
    "    args = transformers.TrainingArguments(\n",
    "        f\"{model_name}-finetuned-{task}-Testing\",\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        metric_for_best_model=metric_name,\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "\n",
    "    evaluator = BertTrainer(\n",
    "        model,\n",
    "        args,\n",
    "        eval_dataset=encoded_dataset['validation'],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    return evaluator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
